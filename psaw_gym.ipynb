{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b7e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psaw\n",
    "import praw\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8c00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1635c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.today()\n",
    "\n",
    "today_month = today.month\n",
    "today_year = today.year\n",
    "\n",
    "start_year = 2020\n",
    "start_month = 12\n",
    "dates = []\n",
    "while start_year <= today_year:\n",
    "    \n",
    "    if start_year == today_year and start_month > today_month:\n",
    "        break\n",
    "        \n",
    "    dates.append((start_year, start_month))\n",
    "    \n",
    "    start_month += 1\n",
    "    if start_month > 12:\n",
    "        start_year += 1\n",
    "        start_month = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45744881",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\"CrohnsDisease\",\"UlcerativeColitis\",\"IBD\",\"ibs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c5993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ids_in_range(year,month,SR,verbose=True):\n",
    "    print(\"Scraping\",\"r/\"+SR,\"for:\",year,\"-\",month)\n",
    "    \n",
    "    DAY = 60*60*24 # seconds in a day\n",
    "    HOUR = 60*60\n",
    "    \n",
    "    # dates are timestamps in seconds = int(dt.datetime(2020, 1, 1).timestamp())\n",
    "    # 1hour offset for some reason? IGNORED\n",
    "    \n",
    "    start=int(dt.datetime(year, month, 1).timestamp())\n",
    "    if month < 12:\n",
    "        end=int(dt.datetime(year, month+1, 1).timestamp())\n",
    "    else: # if dec 2019\n",
    "        end=int(dt.datetime(2020, 1, 1).timestamp())\n",
    "    \n",
    "    start_epoch = start\n",
    "    end_epoch = start + DAY \n",
    "    # search IDs on a weekly basis\n",
    "    ids = []\n",
    "    while end_epoch <= end:\n",
    "        # add ids to list\n",
    "        #print(\".\")\n",
    "        res = list(api.search_submissions(\n",
    "                            after =start_epoch,\n",
    "                            before=end_epoch + HOUR, \n",
    "                            subreddit=SR,\n",
    "                            #filter=['url','author', 'title', 'subreddit'],\n",
    "                            limit=100))\n",
    "        # debug\n",
    "        if verbose:\n",
    "            print(\"FROM:\",np.intc(start_epoch).astype(\"datetime64[s]\"),\"TO:\",np.intc(end_epoch).astype(\"datetime64[s]\"),)        \n",
    "            print(\"FIRST:\",np.intc(res[-1].created_utc).astype(\"datetime64[s]\"),\"LAST:\",np.intc(res[0].created_utc).astype(\"datetime64[s]\"),)        \n",
    "            print(\"number of posts:\", len(res))\n",
    "        \n",
    "        #append results\n",
    "        for r in res:\n",
    "            ids.append(r.id)\n",
    "        \n",
    "        #update epochs\n",
    "        start_epoch = end_epoch\n",
    "        end_epoch = start_epoch + DAY #60*60*24\n",
    "    \n",
    "    #save csv for that subreddit\n",
    "    print(\"saving...\",SR+\"_\"+str(year)+\"-\"+str(month)+\"_submissions.csv\")\n",
    "    print(len(ids),\"posts\")\n",
    "    pd.DataFrame(ids).drop_duplicates().to_csv(\"./submissions/\"+SR+\"_\"+str(year)+\"-\"+str(month)+\"_submissions.csv\")\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f049d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping r/CrohnsDisease for: 2020 - 12\n",
      "saving... CrohnsDisease_2020-12_submissions.csv\n",
      "0 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mic\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 521\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\mic\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unable to connect to pushshift.io. Max retries exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yy, mm \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mretrieve_ids_in_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCrohnsDisease\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mretrieve_ids_in_range\u001b[1;34m(year, month, SR, verbose)\u001b[0m\n\u001b[0;32m     19\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end_epoch \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# add ids to list\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#print(\".\")\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_submissions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mafter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbefore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHOUR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msubreddit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m#filter=['url','author', 'title', 'subreddit'],\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# debug\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:238\u001b[0m, in \u001b[0;36mPushshiftAPIMinimal._search\u001b[1;34m(self, kind, stop_condition, return_batch, dataset, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{dataset}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{kind}\u001b[39;00m\u001b[38;5;124m/search\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dataset\u001b[38;5;241m=\u001b[39mdataset, kind\u001b[38;5;241m=\u001b[39mkind)\n\u001b[0;32m    237\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;241m.\u001b[39mformat(endpoint\u001b[38;5;241m=\u001b[39mendpoint)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_paging(url):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:215\u001b[0m, in \u001b[0;36mPushshiftAPIMinimal._handle_paging\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(err_msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_results_per_request))\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_nec_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload)\n\u001b[1;32m--> 215\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m data\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:194\u001b[0m, in \u001b[0;36mPushshiftAPIMinimal._get\u001b[1;34m(self, url, payload)\u001b[0m\n\u001b[0;32m    192\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot non 200 code \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to connect to pushshift.io. Max retries exceeded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mException\u001b[0m: Unable to connect to pushshift.io. Max retries exceeded."
     ]
    }
   ],
   "source": [
    "for yy, mm in dates:\n",
    "    retrieve_ids_in_range(year=yy, month=mm, SR=\"CrohnsDisease\",verbose=False)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d33821",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"./submissions/\"\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "x = [pd.read_csv(path,index_col=0) for path in onlyfiles]\n",
    "if len(x) > 0:\n",
    "    x = pd.concat(x)\n",
    "    x.columns= [\"id\"]\n",
    "    x = x.reset_index()\n",
    "    x.to_csv(\"all_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b52bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posts = pd.read_csv('./all_ids.csv',index_col=0)\n",
    "new_posts.columns = ['id','subreddit']\n",
    "print('new posts size:',new_posts.shape, new_posts.drop_duplicates(subset='id').shape)\n",
    "new_posts = new_posts.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "old_posts = pd.read_pickle(\"./all_posts.pickle\")\n",
    "print('old posts size:',old_posts.shape, old_posts.drop_duplicates().shape)\n",
    "\n",
    "posts_to_scrape = new_posts[~new_posts['id'].isin(old_posts['id'])]\n",
    "print('posts_to_scrapesize:',posts_to_scrape.shape)\n",
    "posts_to_scrape = posts_to_scrape.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

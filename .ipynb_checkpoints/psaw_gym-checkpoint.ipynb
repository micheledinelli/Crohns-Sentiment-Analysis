{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74b7e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psaw\n",
    "import praw\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8c00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6220b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.today()\n",
    "\n",
    "today_month = today.month\n",
    "today_year = today.year\n",
    "\n",
    "start_year = 2020\n",
    "start_month = 12\n",
    "dates = []\n",
    "while start_year <= today_year:\n",
    "    \n",
    "    if start_year == today_year and start_month > today_month:\n",
    "        break\n",
    "        \n",
    "    dates.append((start_year, start_month))\n",
    "    \n",
    "    start_month += 1\n",
    "    if start_month > 12:\n",
    "        start_year += 1\n",
    "        start_month = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80212127",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\"CrohnsDisease\",\"UlcerativeColitis\",\"IBD\",\"ibs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6500a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ids_in_range(year,month,SR,verbose=True):\n",
    "    print(\"Scraping\",\"r/\"+SR,\"for:\",year,\"-\",month)\n",
    "    \n",
    "    DAY = 60*60*24 # seconds in a day\n",
    "    HOUR = 60*60\n",
    "    \n",
    "    # dates are timestamps in seconds = int(dt.datetime(2020, 1, 1).timestamp())\n",
    "    # 1hour offset for some reason? IGNORED\n",
    "    \n",
    "    start=int(dt.datetime(year, month, 1).timestamp())\n",
    "    if month < 12:\n",
    "        end=int(dt.datetime(year, month+1, 1).timestamp())\n",
    "    else: # if dec 2019\n",
    "        end=int(dt.datetime(2020, 1, 1).timestamp())\n",
    "    \n",
    "    start_epoch = start\n",
    "    end_epoch = start + DAY \n",
    "    # search IDs on a weekly basis\n",
    "    ids = []\n",
    "    while end_epoch <= end:\n",
    "        # add ids to list\n",
    "        #print(\".\")\n",
    "        res = list(api.search_submissions(\n",
    "                            after =start_epoch,\n",
    "                            before=end_epoch + HOUR, \n",
    "                            subreddit=SR,\n",
    "                            #filter=['url','author', 'title', 'subreddit'],\n",
    "                            limit=100))\n",
    "        # debug\n",
    "        if verbose:\n",
    "            print(\"FROM:\",np.intc(start_epoch).astype(\"datetime64[s]\"),\"TO:\",np.intc(end_epoch).astype(\"datetime64[s]\"),)        \n",
    "            print(\"FIRST:\",np.intc(res[-1].created_utc).astype(\"datetime64[s]\"),\"LAST:\",np.intc(res[0].created_utc).astype(\"datetime64[s]\"),)        \n",
    "            print(\"number of posts:\", len(res))\n",
    "        \n",
    "        #append results\n",
    "        for r in res:\n",
    "            ids.append(r.id)\n",
    "        \n",
    "        #update epochs\n",
    "        start_epoch = end_epoch\n",
    "        end_epoch = start_epoch + DAY #60*60*24\n",
    "    \n",
    "    #save csv for that subreddit\n",
    "    print(\"saving...\",SR+\"_\"+str(year)+\"-\"+str(month)+\"_submissions.csv\")\n",
    "    print(len(ids),\"posts\")\n",
    "    pd.DataFrame(ids).drop_duplicates().to_csv(\"./submissions/\"+SR+\"_\"+str(year)+\"-\"+str(month)+\"_submissions.csv\")\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a77380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping r/CrohnsDisease for: 2020 - 12\n",
      "saving... CrohnsDisease_2020-12_submissions.csv\n",
      "0 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 1\n",
      "saving... CrohnsDisease_2021-1_submissions.csv\n",
      "1196 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mic\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "C:\\Users\\mic\\anaconda3\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving... CrohnsDisease_2021-2_submissions.csv\n",
      "918 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 3\n",
      "saving... CrohnsDisease_2021-3_submissions.csv\n",
      "600 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 4\n",
      "saving... CrohnsDisease_2021-4_submissions.csv\n",
      "839 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 5\n",
      "saving... CrohnsDisease_2021-5_submissions.csv\n",
      "1058 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 6\n",
      "saving... CrohnsDisease_2021-6_submissions.csv\n",
      "1104 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 7\n",
      "saving... CrohnsDisease_2021-7_submissions.csv\n",
      "1039 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 8\n",
      "saving... CrohnsDisease_2021-8_submissions.csv\n",
      "1107 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 9\n",
      "saving... CrohnsDisease_2021-9_submissions.csv\n",
      "989 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 10\n",
      "saving... CrohnsDisease_2021-10_submissions.csv\n",
      "1053 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 11\n",
      "saving... CrohnsDisease_2021-11_submissions.csv\n",
      "1029 posts\n",
      "Scraping r/CrohnsDisease for: 2021 - 12\n",
      "saving... CrohnsDisease_2021-12_submissions.csv\n",
      "0 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 1\n",
      "saving... CrohnsDisease_2022-1_submissions.csv\n",
      "1079 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 2\n",
      "saving... CrohnsDisease_2022-2_submissions.csv\n",
      "910 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 3\n",
      "saving... CrohnsDisease_2022-3_submissions.csv\n",
      "1168 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 4\n",
      "saving... CrohnsDisease_2022-4_submissions.csv\n",
      "1094 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 5\n",
      "saving... CrohnsDisease_2022-5_submissions.csv\n",
      "980 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 6\n",
      "saving... CrohnsDisease_2022-6_submissions.csv\n",
      "1068 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 7\n",
      "saving... CrohnsDisease_2022-7_submissions.csv\n",
      "1177 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 8\n",
      "saving... CrohnsDisease_2022-8_submissions.csv\n",
      "1187 posts\n",
      "Scraping r/CrohnsDisease for: 2022 - 9\n",
      "saving... CrohnsDisease_2022-9_submissions.csv\n",
      "855 posts\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for yy, mm in dates:\n",
    "    retrieve_ids_in_range(year=yy, month=mm, SR=\"CrohnsDisease\",verbose=False)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1d33821",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"./submissions/\"\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "x = [pd.read_csv(path,index_col=0) for path in onlyfiles]\n",
    "if len(x) > 0:\n",
    "    x = pd.concat(x)\n",
    "    x.columns= [\"id\"]\n",
    "    x = x.reset_index()\n",
    "    x.to_csv(\"all_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "558c4dcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (510550579.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [32]\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(df)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "for sr in subreddits:\n",
    "    x = []\n",
    "    for fname in os.listdir('./submissions/'):\n",
    "        if sr in fname:\n",
    "            df = pd.read_csv(join('./submissions/', fname)\n",
    "            #x.append(pd.read_csv(join('./submissions/', fname),index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc2e2075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./submissions/fname\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

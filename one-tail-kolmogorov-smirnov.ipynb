{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f39dfd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3506385632.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/8h/v6jk3q7d5xl_fltyymspzdv40000gn/T/ipykernel_1898/3506385632.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---\n",
    "title: Kolmogorov-Smirnov\n",
    "author: Dinelli Michele\n",
    "description: Preview of Kolmogorov-Smirnov tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3922af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # default='warn'\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import datetime as dt\n",
    "from termcolor import colored\n",
    "from statistics import mean\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as SIA_VADER\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA_NLTK\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "import researchpy as rp\n",
    "import scipy.stats as stats\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('paper')\n",
    "style.use('ggplot')\n",
    "matplotlib.rcParams['font.family'] = 'helvetica'\n",
    "matplotlib.rcParams['figure.titlesize'] = 'large'\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c2f2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_submissions():\n",
    "    path = './submissions_scraped/'\n",
    "    files = []\n",
    "    for filename in os.listdir(path):\n",
    "        files.append(pd.read_csv(os.path.join(path, filename)))\n",
    "    \n",
    "    files = pd.concat(files)\n",
    "    df_submissions = pd.DataFrame(files)\n",
    "    df_submissions.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_submissions.dropna(inplace=True)\n",
    "    return df_submissions\n",
    "\n",
    "def import_submissions_previous():\n",
    "    path = './submissions_scraped_previous/'\n",
    "    files = []\n",
    "    for filename in os.listdir(path):\n",
    "        files.append(pd.read_csv(os.path.join(path, filename)))\n",
    "    \n",
    "    files = pd.concat(files)\n",
    "    df_submissions = pd.DataFrame(files)\n",
    "    df_submissions.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    return df_submissions\n",
    "\n",
    "def import_comments():\n",
    "    df_comments = pd.read_csv('./comments_scraped/comments.csv')\n",
    "    df_comments.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_comments.dropna(inplace=True)\n",
    "    return df_comments\n",
    "\n",
    "def import_comments_previous():\n",
    "    df_comments = pd.read_csv('./comments_scraped_previous/comments.csv')\n",
    "    df_comments.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    return df_comments\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower()\n",
    "    text = re.sub('^\\[removed\\]|^\\[deleted\\]', '', str(text))\n",
    "    text = re.sub('^\\[deleted by user\\]', '', str(text))\n",
    "    text = re.sub('^nan', '', str(text))\n",
    "    text = re.sub(r'#', '', str(text))\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", str(text))\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', str(text))\n",
    "    text = re.sub(r'www\\S+', '', str(text))\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "def is_positive(compound):\n",
    "    if compound > 0.05:\n",
    "        return 1\n",
    "    elif compound < -0.05:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convert_label(text):\n",
    "    if text == 'pos':\n",
    "        return 1\n",
    "    elif text == 'neg':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53ebb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['CrohnsDisease', 'IBD', 'UlcerativeColitis', 'ibs']\n",
    "colors = ['#cc5a49', '#4586ac', '#9e97cc', '#777777']\n",
    "\n",
    "# Data before 12-2020\n",
    "df_sub_prev = import_submissions_previous()\n",
    "df_comm_prev = import_comments_previous()\n",
    "\n",
    "# Data after 12-2020\n",
    "df_sub_aft = import_submissions()\n",
    "df_comm_aft = import_comments()\n",
    "\n",
    "df_submissions = pd.concat([df_sub_prev, df_sub_aft])\n",
    "df_comments = pd.concat([df_comm_prev, df_comm_aft])\n",
    "\n",
    "df_submissions['title_and_body'] = df_submissions['title'] + ' ' + df_submissions['body']\n",
    "df_submissions['title_and_body'] = df_submissions['title_and_body'].apply(lambda x: clean_text(str(x)))\n",
    "df_comments['body'] = df_comments.body.apply(lambda x: clean_text(str(x)))\n",
    "\n",
    "df_submissions = df_submissions[df_submissions['title_and_body'] != '']\n",
    "df_comments = df_comments[df_comments['body'] != '']\n",
    "\n",
    "df_submissions['created'] = pd.to_datetime(df_submissions['created'])\n",
    "df_comments['created'] = pd.to_datetime(df_comments['created'])\n",
    "df_comments = df_comments[df_comments['created'] < dt.datetime(2022, 10, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff91e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "790c82eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sia_vader \u001b[38;5;241m=\u001b[39m SIA_VADER()\n\u001b[0;32m      2\u001b[0m roberta \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcardiffnlp/twitter-roberta-base-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(roberta)\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(roberta)\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:992\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, key)\n\u001b[1;32m--> 992\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:980\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    978\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "sia_vader = SIA_VADER()\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['neg', 'neu', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions = df_submissions[df_submissions['created'] != '21-02']\n",
    "df_submissions = df_submissions[df_submissions['created'] != '21-03']\n",
    "df_submissions = df_submissions[df_submissions['created'] != '21-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f109ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "compounds = []\n",
    "for post in tqdm(df_submissions.title_and_body, desc='Analyzing with vader'):\n",
    "scores = sia_vader.polarity_scores(post)\n",
    "sentiments.append(sia_vader.polarity_scores(post))\n",
    "compounds.append(scores['compound'])\n",
    "df_submissions['sia_vader'] = sentiments\n",
    "df_submissions['compound'] = compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f50c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submissions.created = df_submissions.created.apply(lambda x: x.strftime('%y-%m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c64b95",
   "metadata": {},
   "source": [
    "### Performing Kolmogorov‑Smirnov one tailed test\n",
    "\n",
    "By setting **alternative=greater**꞉\n",
    "\n",
    "Null hypothesis is that F(x) <= G(x) for all x; the alternative is that F(x) > G(x) for at least one x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914205c",
   "metadata": {},
   "source": [
    "### Test 1꞉ Submission count꞉\n",
    "**before pandemic vs after pandemic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs_per_month = df_submissions.groupby(['created', 'subreddit']).count().reset_index()\n",
    "\n",
    "fig, [[ax1, ax2], [ax3, ax4]] = plt.subplots(figsize=(20,14), nrows=2, ncols=2)\n",
    "\n",
    "plt.suptitle('Submission count per month', fontsize=25)\n",
    "\n",
    "ax1.set_title('r/CrohnsDisease')\n",
    "cr = df_subs_per_month[df_subs_per_month['subreddit'] == 'CrohnsDisease']\n",
    "ax1.set_ylabel('count')\n",
    "ax1.axvline(6, color='black', label='First registered cases in Wuhan')\n",
    "ax1.axvline(8, color='blue', label='Covid spreads in the USA')\n",
    "\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "sns.lineplot(x=cr.created, y=cr.id, ax=ax1, color=colors[0])\n",
    "\n",
    "ax2.set_title('r/ibs')\n",
    "ibs = df_subs_per_month[df_subs_per_month['subreddit'] == 'ibs']\n",
    "ax2.set_ylabel('count')\n",
    "ax2.axvline(6, color='black', label='First registered cases in Wuhan')\n",
    "ax2.axvline(8, color='blue', label='Covid spreads in the USA')\n",
    "\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "sns.lineplot(x=ibs.created, y=ibs.id, ax=ax2, color=colors[1])\n",
    "\n",
    "ax3.set_title('r/UlcerativeColitis')\n",
    "ulc = df_subs_per_month[df_subs_per_month['subreddit'] == 'UlcerativeColitis']\n",
    "ax3.set_ylabel('count')\n",
    "ax3.axvline(6, color='black', label='First registered cases in Wuhan')\n",
    "ax3.axvline(8, color='blue', label='Covid spreads in the USA')\n",
    "\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)\n",
    "sns.lineplot(x=ulc.created, y=ulc.id, ax=ax3, color=colors[2])\n",
    "\n",
    "ax4.set_title('r/IBD')\n",
    "ibd = df_subs_per_month[df_subs_per_month['subreddit'] == 'IBD']\n",
    "ax4.set_ylabel('count')\n",
    "ax4.axvline(6, color='black', label='First registered cases in Wuhan')\n",
    "ax4.axvline(8, color='blue', label='Covid spreads in the USA')\n",
    "\n",
    "plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)\n",
    "sns.lineplot(x=ibd.created, y=ibd.id, ax=ax4, color=colors[3])\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56747086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_counts = df_submissions.groupby(['created', 'subreddit']).count().reset_index()\n",
    "\n",
    "p_values = []\n",
    "statistics = []\n",
    "dfs = []\n",
    "for sr in subreddits:\n",
    "    a = df_sub_counts[(df_sub_counts['subreddit'] == sr) & (df_sub_counts['created'] <= '20-02')]\n",
    "    b = df_sub_counts[(df_sub_counts['subreddit'] == sr) & (df_sub_counts['created'] > '20-02')]\n",
    "    p_values.append((stats.kstest(a.id, b.id).pvalue, sr, 'full period (Feb 2020 to September 2022)'))\n",
    "    statistics.append((stats.kstest(a.id, b.id).statistic, sr, 'full period (Feb 2020 to Sept 2022)'))\n",
    "    a['type'] = 'before pandemic (Jun 2019 - Feb 2020)'\n",
    "    b['type'] = 'during pandemic (Feb 2020 - Sept 2022)'\n",
    "    dsr = pd.concat([a, b])\n",
    "    dsr['subreddit'] = sr\n",
    "    dfs.append(dsr)\n",
    "    print(colored(f'\\nSubreddit: {sr}', color='blue'))\n",
    "    print('Period: before pandemic (Jun 2019 - Feb 2020) vs during pandemic (Feb 2020 - Sept 2022)')\n",
    "    print(stats.kstest(a.id, b.id))\n",
    "          \n",
    "p_values = pd.DataFrame(p_values, columns=['p_value', 'subreddit', 'type'])\n",
    "statistics = pd.DataFrame(statistics, columns=['statistic', 'subreddit', 'type'])\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for df in dfs:\n",
    "    result = pd.concat([result, df])\n",
    "\n",
    "result.rename(columns={'id': 'submission_count'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
